# 朴素贝叶斯法
基于**贝叶斯定理**和**特征条件独立**假设的分类方法
- 先根据**特征条件独立**学习联合概率分布
- 再基于此模型，利用贝叶斯定理给定 x 求出后验概率 y,选 y 最大的

## 基本贝叶斯公式
- `P(A|B) = P(A∩B)/P(B)` 即 `P(A∩B) = P(A|B)·P(B) = P(B|A)·P(A)`
- 则 `P(A|B) = P(B|A)·P(A) / P(B)`
  - `P(A|B)` 是 B 发生时，发生 A 的概率
  - `P(A∩B)` 是 A、B 同时发生的概率
- 由全概率公式 `P(B) = sum(P(B|Ai)·P(Ai))`
- 则 `P(A|B) = P(B|A)·P(A) / sum(P(B|Ai)·P(Ai))`

## 先验概率与后验概率
### 先验概率
指根据以往经验和分析得到的概率，P(A)、P(B)

### 后验概率
在得到“结果”的信息后重新修正的概率，后验概率实际上就是条件概率，P(A|B)

## 基本方法
学习联合概率分布
- 学习先验概率分布和条件概率分布，于是学习到联合概率分布
- 条件概率分布作了条件独立假设（这也是朴素之名的来源）
  - 这样 `P(C|F1,...,Fn) = P(C) * P(F1|C) * P(F2|C,F1) * ... * P(Fn|C,F1,F2...,Fn-1)`  
  - 根据条件独立假设 `P(C|F1,...,Fn) = P(C) * P(F1|C) * P(F2|C) * ... * P(Fn|C)`

根据学习的模型计算后验概率分布 `P(Y=ck|X=x)`
- 用贝叶斯公式 `P(A|B) = P(B|A)·P(A) / sum(P(B|Ai)·P(Ai))`
- 带入条件独立假设的公式
- 最后获得一个关于 ck 的方程
- 使得后验概率最大化可得到期望风险最小化

## 先验概率分布和条件概率分布的计算方法
- 极大似然估计
  - 但会出现概率为0的情况

- 贝叶斯估计
  - 随机变量的频数上加个正数 λ > 0
  - λ = 0 为极大似然估计
  - λ = 1 为拉普拉斯平滑，常用
